\section{Related Work}

\subsection{Adversarial Perturbations for Voice Protection}

Recent work has explored adversarial perturbations as a proactive defense against voice cloning. SafeSpeech~\citep{safespeech} adds imperceptible noise optimized to degrade speaker embedding quality, preventing attackers from training high-fidelity TTS models. VoiceBlock~\citep{voiceblock} extends this approach with improved optimization strategies and evaluation protocols. While these methods demonstrate effectiveness in controlled settings, they face a fundamental limitation: imperceptible perturbations are inherently fragile to common audio processing operations.

Standard audio preprocessing such as MP3 compression, format conversion, and resampling can attenuate or remove imperceptible perturbations. More critically, speech enhancement techniques pose a severe threat to these defenses. Traditional denoising methods such as spectral subtraction and Wiener filtering~\citep{denoising}, as well as modern deep learning-based enhancement~\citep{demucs}, are specifically designed to separate and remove signal components that differ from clean speech. Since imperceptible perturbations are by definition subtle deviations from the original signal, they are precisely the type of artifacts that enhancement algorithms target for removal. This creates an asymmetric advantage for attackers who can apply readily available audio enhancement tools to neutralize protection mechanisms.

Our work departs from the imperceptibility paradigm by deliberately using audible but contextually natural noise. We hypothesize that scene-consistent background noise, being perceptually meaningful and semantically coherent with the speech content, is fundamentally harder to separate without degrading speech quality. This trade-off between imperceptibility and robustness represents a key design choice that distinguishes our approach from prior work.

\subsection{Data Poisoning and Watermarking}

Data poisoning techniques inject carefully crafted perturbations into training data to degrade model performance~\citep{poisoning}. However, these methods typically assume control over the training process, which does not hold in voice cloning threat scenarios. Audio watermarking~\citep{watermarking} embeds traceable signals into audio for post-attack detection and attribution. While complementary to our work, watermarking addresses a different goal: detecting rather than preventing voice cloning.

\subsection{Acoustic Scene Classification}

Acoustic scene classification (ASC) aims to identify the environmental context of audio recordings~\citep{tau_dataset}. State-of-the-art ASC systems use deep convolutional networks trained on large-scale datasets such as TAU Urban Acoustic Scenes~\citep{tau_dataset}. SceneGuard leverages ASC to ensure that protective noise matches the acoustic context of input speech, creating a more natural and robust defense compared to context-agnostic perturbations.

